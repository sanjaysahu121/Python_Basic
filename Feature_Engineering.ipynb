{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655c796c-9eac-4ef0-aa8e-e91f5c7de4aa",
   "metadata": {},
   "source": [
    "# Assignment Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee69e2-6886-43b8-8e47-1e415d58cea7",
   "metadata": {},
   "source": [
    "### Q1.\tWhat is a parameter?\n",
    "\n",
    "- A parameter is a configuration variable internal to the model whose value can be estimated from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153699a-7f6d-4c46-ada7-03e0b97ccf7c",
   "metadata": {},
   "source": [
    "# Q2.What is correlation? What does negative correlation mean?\n",
    "- Correlation is a statistical measure that expresses the extent to which two variables are linearly related. It describes how change in one variable is associated with a change in another variable.\n",
    "\n",
    "- Negative correlation means that as the value of one variable increases, the value of the other variable tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad016f55-d1c0-4bc9-a054-44986b931b61",
   "metadata": {},
   "source": [
    "# Q3.Define Machine Learning. What are the main components in Machine Learning?\n",
    "\n",
    "- Machine Learning is a focus on creating algorithms and statistical models to let computers learn and make prediction without explicitly programmed is know as machine learning.\n",
    "- **The main components in Machine Learning**\n",
    "  1. Data\n",
    "  2. Features\n",
    "  3. Algorithms/model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285baa35-8fd5-4ae5-8220-1a177da26e2f",
   "metadata": {},
   "source": [
    "# Q4.How does loss value help in determining whether the model is good or not?\n",
    "- The loss value is a numerical representation of the \"error\" or the difference between the model's prediction and the actual target value.\n",
    "  - Indicator of Accuracy\n",
    "  - Model Evaluation\n",
    "  - Optimization Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb3f91-b620-4f18-87ee-822e96dda3a3",
   "metadata": {},
   "source": [
    "# Q5.What are continuous and categorical variables?\n",
    "\n",
    "  1. Continuous Variables\n",
    "     - Continuous variables represent numeric values that can take any value within a range or interval.\n",
    "     - Example -> Height,Weight\n",
    "       \n",
    "  2. Categorical Variables\n",
    "     - Categorical variables represent groups, labels, or categories rather than numbers with mathematical meaning.\n",
    "     - Example -> Gender, colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c911f09-3d8c-4656-9aa6-b96205602fb0",
   "metadata": {},
   "source": [
    "# Q6.How do we handle categorical variables in Machine Learning? What are the common t echniques?\n",
    "- Data Encoding is the primary method for handling the categorical values.\n",
    "- **Two most common techniques used in Python**\n",
    "   - Label Encoding -> LabelEncoder\n",
    "   - One Hot Encoding -> OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217b787-6f0d-4b3c-b916-4e9b236e5ebe",
   "metadata": {},
   "source": [
    "# Q7.What do you mean by training and testing a dataset?\n",
    "- The training set is the portion of the data used to \"teach\" the model. During this phase:-\n",
    "   - The model looks for patterns, relationships, and correlations between the input features (X) and the target labels (y).\n",
    "   - The model.fit() is used for model training.\n",
    "     \n",
    "\n",
    "- The test set is a separate portion of the data used to evaluate the model after it has been trained.\n",
    "  - The model.predict() is used for model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbefd7e-a8cb-4823-aba1-4e89fa0fe542",
   "metadata": {},
   "source": [
    "# Q8.What is sklearn.preprocessing?\n",
    "- Scikit learn library is used for data preprocessing\n",
    "  - Data Transformation\n",
    "  - Scaling and normalization\n",
    "  - Handling CAtegorical Data\n",
    "- Common Tool in this module\n",
    "   - StandardScaler or MinMaxScaler\n",
    "   - LabelEncoder or OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98780d98-8d8a-4e06-8d07-28f7cdf11c34",
   "metadata": {},
   "source": [
    "# 9.What is a Test set?\n",
    "- Unseen Data: It consists of data that the model has never seen during the training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7328d69-e003-4ff7-8342-ec9ade39de62",
   "metadata": {},
   "source": [
    "# Q10.How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
    "To prepare data for model fitting, we divide the dataset into two distinct sets: training and testing.\n",
    "\n",
    "The Process: We use specific libraries to automate this split, ensuring the model learns from one portion and is evaluated on another.\n",
    "\n",
    "Library Used: In Python, this is typically done using the train_test_split function from the sklearn.model_selection module.\n",
    "\n",
    "Purpose: Splitting data helps determine if the model is \"good\" by checking its performance (via loss values) on the unseen test set.\n",
    "\n",
    "### Approach a Machine Learning Problem by using\n",
    "  \n",
    "Understand the Problem: Define whether you are dealing with continuous variables (regression) or categorical variables (classification).\n",
    "\n",
    "Exploratory Data Analysis (EDA): You must perform EDA before fitting a model to understand the underlying patterns and relationships in the data.\n",
    "\n",
    "Find Correlations: Identify how variables relate to one another using tools like a correlation matrix to see if they move together (positive correlation) or in opposite directions (negative correlation).\n",
    "\n",
    "Feature Engineering & Scaling: Use sklearn.preprocessing to handle categorical variables through encoding and apply feature scaling to ensure all variables are on a similar scale.\n",
    "\n",
    "Data Splitting: Divide your data into a training set and a test set.\n",
    "\n",
    "Model Fitting: Use model.fit() with the required training arguments to train the model.\n",
    "\n",
    "Prediction & Evaluation: Use model.predict() to test the model on new data and analyze the loss value to determine accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f168da83-778b-4bca-8f33-8703f5d59a06",
   "metadata": {},
   "source": [
    "# Q11.Why do we have to perform EDA before fitting a model to the data?\n",
    "- Before fitting a model to the data we need to perform EDA beacuse -> IF in the dataset there are some noise data like null value , some of the data is not in correct data types , or if dataset is not in correct formate then the model should not train properly and it give baised answer or prediction i.e we use EDA before fitting a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b01e39-d347-4db8-b7dc-e16d06b51e92",
   "metadata": {},
   "source": [
    "# Q12.What is correlation?\n",
    "- Correlation is a statistical measure that expresses the extent to which two variables are linearly related. It describes how change in one variable is associated with a change in another variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ea114-a335-47fe-b361-33ec7fa36eff",
   "metadata": {},
   "source": [
    "# Q13.What does negative correlation mean?\n",
    "- Negative correlation means that as the value of one variable increases, the value of the other variable tends to decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01dd5d-91a8-41fd-8691-512d28048872",
   "metadata": {},
   "source": [
    "# Q14.How can you find correlation between variables in Python?\n",
    "- By using Pandas library in python \n",
    "- .corr() -> for numerical columns\n",
    "- we can maake heatmap by using seaborn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2c6e8-ef93-49ff-b504-5f384cc99391",
   "metadata": {},
   "source": [
    "# Q15.What is causation? Explain difference between correlation and causation with an example.\n",
    "- Causation means that one event is the direct result of the occurrence of the other event.\n",
    "   - Example\n",
    "      - If we change variable A, variable B will change because of that action.\n",
    "##### Difference between Correlation and causation \n",
    "##### Correlation \n",
    "- A statistical measure describing how two variables move together.\n",
    "- If A increases, B might increase, but A did not necessarily force B to change.\n",
    "\n",
    "##### Causation\n",
    "- Indicates that one event is the direct result of the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87799818-8d54-4ee7-ba53-f30205624d52",
   "metadata": {},
   "source": [
    "# Q16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "\n",
    "- In Machine Learning, an Optimizer is an algorithm or method used to change the attributes of your neural network, such as weights and learning rate, to reduce the losses. The goal is to reach the global minimum where the loss is lowest.\n",
    "\n",
    "  #### Different types of optimizers\n",
    "\n",
    "##### 1. Gradient Descent (GD)\n",
    "- The most basic type of optimizer. It calculates the gradient of the loss function with respect to the weights for the entire dataset before updating them.\n",
    "    - Example: If you are training a model on 1,000 images, GD waits to see all 1,000 images, calculates the average error, and then takes one step.\n",
    "\n",
    "#### 2. Stochastic Gradient Descent (SGD)\n",
    "- SGD updates the weights frequentlyâ€”after seeing each individual training example.\n",
    "     - Example: After seeing just one image out of 1,000, the model immediately adjusts its weights.\n",
    " \n",
    "#### 3. Mini-Batch Gradient Descent\n",
    "- A middle ground between GD and SGD. It splits the training data into small groups (batches).\n",
    "    - Example: If you have 1,000 images, you might use a batch size of 32. The model updates the weights after every 32 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa4647-fac7-42c2-ab51-02bbd82d1348",
   "metadata": {},
   "source": [
    "# Q17.What is sklearn.linear model?\n",
    "- sklearn.linear_model is a module within the Scikit-Learn library in Python that provides a set of algorithms for performing linear modeling. It is primarily used for predicting continuous values (Regression) or categorizing data (Classification) by finding a linear relationship between input features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b0d5d6-4eea-4221-a73c-6faeb2d85671",
   "metadata": {},
   "source": [
    "# Q18.What does model.fit() do? What arguments must be given?\n",
    "- In machine learning, specifically within libraries like Scikit-Learn or TensorFlow/Keras, model.fit() is the core function used to train the model.\n",
    "\n",
    "- It is the process where the algorithm \"learns\" by looking at the data, identifying patterns, and adjusting its internal parameters (weights) to minimize error.\n",
    "##### Pattern Recognition \n",
    "##### Error Calculation\n",
    "##### Optimization\n",
    "##### Convergence\n",
    "### .fit() -> we need to provide two mandorty argument (x , y ) i.e Feature Matrix / Input Data and  Target vector / Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344671a-4419-4c94-a5bb-8467c39aa7d1",
   "metadata": {},
   "source": [
    "# Q19.What does model.predict() do? What arguments must be given?\n",
    "- The .predict() method uses the \"knowledge\" (weights and patterns) the model learned during the training phase to generate outputs for new, unseen data.\n",
    "\n",
    "- For Regression: It returns a continuous numerical value (e.g., predicting the exact Salary of an employee).\n",
    "\n",
    "- For Classification: It returns the predicted label or category (e.g., predicting if a patient is ckd or notckd).\n",
    "\n",
    "#### .predict() -> we only need one primary argument i.e x(Feature Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2d195-8bd4-4f0e-a343-264deb9a9e5a",
   "metadata": {},
   "source": [
    "# Q20.What are continuous and categorical variables?\n",
    " ####  1.Categorical Variables\n",
    " - Categorical variables (also known as qualitative variables) represent groups or categories. They describe a quality or characteristic rather than a measurement.\n",
    "     - Example: Education level etc.\n",
    "#### 2. Continuous Variables\n",
    "- Continuous variables (a type of quantitative variable) represent measurements and can take any numeric value within a specific range.\n",
    "  - Examples: Height, weight, temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eaa445-af03-45bc-838a-48bc6f3ebb49",
   "metadata": {},
   "source": [
    "# Q21.What is feature scaling? How does it help in Machine Learning?\n",
    "- Feature Scaling is a data preprocessing technique used to normalize the range of independent variables or features of data and its usually between 0 and 1 or centered around zero.\n",
    "##### Its help in machine learning \n",
    "- 1. Faster Convergence for Gradient Descent\n",
    "  2. Accuracy for Distance-Based Algorithms\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3019ee5-f865-443e-9b6d-3134267ff40c",
   "metadata": {},
   "source": [
    "# Q22.How do we perform scaling in Python?\n",
    "- We have various method by using sklearn.preprocessing import from StandardScaler and by using OneHotEncoder\n",
    "- By using Normalization(min max scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231b3d0-4c1d-4724-8fe3-efcde1d9b93d",
   "metadata": {},
   "source": [
    "# Q23.What is sklearn.preprocessing?\n",
    "- Scikit learn library is used for data preprocessing\n",
    "  - Data Transformation\n",
    "  - Scaling and normalization\n",
    "  - Handling CAtegorical Data\n",
    "- Common Tool in this module\n",
    "   - StandardScaler or MinMaxScaler\n",
    "   - LabelEncoder or OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f41f3a-e2b8-4776-9431-f38739726bec",
   "metadata": {},
   "source": [
    "# Q24.How do we split data for model fitting (training and testing) in Python?\n",
    "- The most standard and efficient way to split data for model fitting is by using the train_test_split function from the Scikit-Learn library.\n",
    "- This process ensures that your model is trained on one portion of the data and evaluated on a separate, \"unseen\" portion to check its real-world performance.\n",
    "   - To split your data, you typically use the sklearn.model_selection module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a365a-ca87-4cc9-a67c-40daeebdf438",
   "metadata": {},
   "source": [
    "# Q25.Explain data encoding?\n",
    "- Conerting the string data into numerical data.\n",
    "- we have different methods such as :\n",
    "    - Nominal / OneHotEncoded\n",
    "    - label and ordinal\n",
    "    - target guided ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84028cf1-8b07-4ca1-86c8-5e07b55fb3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
